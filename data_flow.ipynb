{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (0.3.4)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (from requests->kagglehub) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (from requests->kagglehub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (from requests->kagglehub) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fetching data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dataenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/varpit94/apple-stock-data-updated-till-22jun2021?dataset_version_number=8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 205k/205k [00:00<00:00, 7.76MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: /Users/minhnguyen/.cache/kagglehub/datasets/varpit94/apple-stock-data-updated-till-22jun2021/versions/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"varpit94/apple-stock-data-updated-till-22jun2021\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv \"/Users/minhnguyen/.cache/kagglehub/datasets/varpit94/apple-stock-data-updated-till-22jun2021/versions/8\" \"C:\\Users\\hweinguyen\\Final Project\\Architecture\\AAPL.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-12-12</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.100323</td>\n",
       "      <td>469033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-12-15</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.095089</td>\n",
       "      <td>175884800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.088110</td>\n",
       "      <td>105728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-12-17</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.090291</td>\n",
       "      <td>86441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-12-18</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.092908</td>\n",
       "      <td>73449600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close  Adj Close     Volume\n",
       "0  1980-12-12  0.128348  0.128906  0.128348  0.128348   0.100323  469033600\n",
       "1  1980-12-15  0.122210  0.122210  0.121652  0.121652   0.095089  175884800\n",
       "2  1980-12-16  0.113281  0.113281  0.112723  0.112723   0.088110  105728000\n",
       "3  1980-12-17  0.115513  0.116071  0.115513  0.115513   0.090291   86441600\n",
       "4  1980-12-18  0.118862  0.119420  0.118862  0.118862   0.092908   73449600"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('AAPL.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>14.621429</td>\n",
       "      <td>14.732143</td>\n",
       "      <td>14.607143</td>\n",
       "      <td>14.686786</td>\n",
       "      <td>12.575917</td>\n",
       "      <td>302220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>14.642857</td>\n",
       "      <td>14.810000</td>\n",
       "      <td>14.617143</td>\n",
       "      <td>14.765714</td>\n",
       "      <td>12.643503</td>\n",
       "      <td>260022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>14.819643</td>\n",
       "      <td>14.948214</td>\n",
       "      <td>14.738214</td>\n",
       "      <td>14.929643</td>\n",
       "      <td>12.783874</td>\n",
       "      <td>271269600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7838</th>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>14.991786</td>\n",
       "      <td>15.098214</td>\n",
       "      <td>14.972143</td>\n",
       "      <td>15.085714</td>\n",
       "      <td>12.917513</td>\n",
       "      <td>318292800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7839</th>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>15.196429</td>\n",
       "      <td>15.276786</td>\n",
       "      <td>15.048214</td>\n",
       "      <td>15.061786</td>\n",
       "      <td>12.897022</td>\n",
       "      <td>394024400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Open       High        Low      Close  Adj Close  \\\n",
       "7835 2012-01-03  14.621429  14.732143  14.607143  14.686786  12.575917   \n",
       "7836 2012-01-04  14.642857  14.810000  14.617143  14.765714  12.643503   \n",
       "7837 2012-01-05  14.819643  14.948214  14.738214  14.929643  12.783874   \n",
       "7838 2012-01-06  14.991786  15.098214  14.972143  15.085714  12.917513   \n",
       "7839 2012-01-09  15.196429  15.276786  15.048214  15.061786  12.897022   \n",
       "\n",
       "         Volume  \n",
       "7835  302220800  \n",
       "7836  260022000  \n",
       "7837  271269600  \n",
       "7838  318292800  \n",
       "7839  394024400  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "filter_year_df = df[(df['Date'].dt.year >= 2012 ) & (df['Date'].dt.year <= 2022)]\n",
    "filter_year_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         False\n",
       "Open         False\n",
       "High         False\n",
       "Low          False\n",
       "Close        False\n",
       "Adj Close    False\n",
       "Volume       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_year_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Open, High, Low, Close, Adj Close, Volume]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_year_df[filter_year_df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>14.621429</td>\n",
       "      <td>14.732143</td>\n",
       "      <td>14.607143</td>\n",
       "      <td>14.686786</td>\n",
       "      <td>12.575917</td>\n",
       "      <td>302220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>14.642857</td>\n",
       "      <td>14.810000</td>\n",
       "      <td>14.617143</td>\n",
       "      <td>14.765714</td>\n",
       "      <td>12.643503</td>\n",
       "      <td>260022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>14.819643</td>\n",
       "      <td>14.948214</td>\n",
       "      <td>14.738214</td>\n",
       "      <td>14.929643</td>\n",
       "      <td>12.783874</td>\n",
       "      <td>271269600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>14.991786</td>\n",
       "      <td>15.098214</td>\n",
       "      <td>14.972143</td>\n",
       "      <td>15.085714</td>\n",
       "      <td>12.917513</td>\n",
       "      <td>318292800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>15.196429</td>\n",
       "      <td>15.276786</td>\n",
       "      <td>15.048214</td>\n",
       "      <td>15.061786</td>\n",
       "      <td>12.897022</td>\n",
       "      <td>394024400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Open       High        Low      Close  Adj Close     Volume\n",
       "0 2012-01-03  14.621429  14.732143  14.607143  14.686786  12.575917  302220800\n",
       "1 2012-01-04  14.642857  14.810000  14.617143  14.765714  12.643503  260022000\n",
       "2 2012-01-05  14.819643  14.948214  14.738214  14.929643  12.783874  271269600\n",
       "3 2012-01-06  14.991786  15.098214  14.972143  15.085714  12.917513  318292800\n",
       "4 2012-01-09  15.196429  15.276786  15.048214  15.061786  12.897022  394024400"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df = filter_year_df.sort_values(by='Date', ascending=True).reset_index(drop=True)\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_csv('Cleaned_Apple_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Put the raw data and cleaned data into HDFS for further use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hdfs\n",
      "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docopt (from hdfs)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.7.0 in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (from hdfs) (2.32.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (from hdfs) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (from requests>=2.7.0->hdfs) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (from requests>=2.7.0->hdfs) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (from requests>=2.7.0->hdfs) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (from requests>=2.7.0->hdfs) (2024.7.4)\n",
      "Building wheels for collected packages: hdfs, docopt\n",
      "  Building wheel for hdfs (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34325 sha256=d2de63ad7a80f9233288b68d1f02e23e321e12a79dedc54d4439268a2513db76\n",
      "  Stored in directory: /Users/minhnguyen/Library/Caches/pip/wheels/97/ae/d9/536505928dd3a458b206013b02625df8f12d22fa154f2bfd65\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=543d6cd882bec049309e589a9eda21ead7b056595084c0f5aa7b3637a87d0e14\n",
      "  Stored in directory: /Users/minhnguyen/Library/Caches/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "Successfully built hdfs docopt\n",
      "Installing collected packages: docopt, hdfs\n",
      "Successfully installed docopt-0.6.2 hdfs-2.7.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadoop 3.4.0\n",
      "Source code repository git@github.com:apache/hadoop.git -r bd8b77f398f626bb7791783192ee7a5dfaeec760\n",
      "Compiled by root on 2024-03-04T06:35Z\n",
      "Compiled on platform linux-x86_64\n",
      "Compiled with protoc 3.21.12\n",
      "From source with checksum f7fe694a3613358b38812ae9c31114e\n",
      "This command was run using /Users/minhnguyen/hadoop-3.4.0/share/hadoop/common/hadoop-common-3.4.0.jar\n"
     ]
    }
   ],
   "source": [
    "!hdfs version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69219 SecondaryNameNode\n",
      "69429 ResourceManager\n",
      "68951 NameNode\n",
      "69641 NodeManager\n",
      "79711 Jps\n",
      "69070 DataNode\n"
     ]
    }
   ],
   "source": [
    "!jps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Data to HDFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-07 17:29:28,136 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "ls: `/user/minhnguyen/data': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/minhnguyen/data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in HDFS directory: ['cleaned_data', 'raw_data']\n"
     ]
    }
   ],
   "source": [
    "from hdfs import InsecureClient\n",
    "\n",
    "# Connect to the HDFS \n",
    "client = InsecureClient('http://localhost:9870', user='minhnguyen')\n",
    "\n",
    "# Define the local raw_file cleaned_file path \n",
    "raw_data_path = '/Users/minhnguyen/Workspace/FINALPROJECT/ARCHITECTURE/AAPL.csv'\n",
    "cleaned_data_path = '/Users/minhnguyen/Workspace/FINALPROJECT/ARCHITECTURE/Cleaned_Apple_Data.csv'\n",
    "\n",
    "# Define the HDFS raw_file, cleaned_file path \n",
    "raw_hdfs_path = '/apple_stock_data/raw_data/Apple_Stock_1980_2022.csv'\n",
    "cleaned_hdfs_path = '/apple_stock_data/cleaned_data/Cleaned_Apple_Stock.csv'\n",
    "\n",
    "# Upload the file to HDFS\n",
    "client.upload(raw_hdfs_path, raw_data_path)\n",
    "client.upload(cleaned_hdfs_path, cleaned_data_path)\n",
    "\n",
    "# List files in the HDFS directory\n",
    "files_in_hdfs = client.list('/apple_stock_data')\n",
    "print(\"Files in HDFS directory:\", files_in_hdfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocess with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('AppleStockAnomalyDetection').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.2.90:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>AppleStockAnomalyDetection</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x105bd5f10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: string (nullable = true)\n",
      " |-- High: string (nullable = true)\n",
      " |-- Low: string (nullable = true)\n",
      " |-- Close: string (nullable = true)\n",
      " |-- Adj Close: string (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"Cleaned_Apple_Data.csv\")\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Open: float (nullable = true)\n",
      " |-- High: float (nullable = true)\n",
      " |-- Low: float (nullable = true)\n",
      " |-- Close: float (nullable = true)\n",
      " |-- Adj Close: float (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col \n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "df_pyspark = df_pyspark.select(\n",
    "  to_date(col(\"Date\"), \"yyyy-MM-dd\").alias(\"Date\"),\n",
    "  col(\"Open\").cast(\"float\"),\n",
    "  col(\"High\").cast(\"float\"),\n",
    "  col(\"Low\").cast(\"float\"),\n",
    "  col(\"Close\").cast(\"float\"),\n",
    "  col(\"Adj Close\").cast(\"float\"),\n",
    "  col(\"Volume\").cast(\"int\"),\n",
    ")\n",
    "\n",
    "df_pyspark = df_pyspark.na.drop()\n",
    "\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date=datetime.date(2012, 1, 3), Open=14.621429443359375, High=14.73214340209961, Low=14.60714340209961, Close=14.686785697937012, Adj Close=12.57591724395752, Volume=302220800),\n",
       " Row(Date=datetime.date(2012, 1, 4), Open=14.64285659790039, High=14.8100004196167, Low=14.617142677307129, Close=14.765713691711426, Adj Close=12.643503189086914, Volume=260022000),\n",
       " Row(Date=datetime.date(2012, 1, 5), Open=14.819643020629883, High=14.948213577270508, Low=14.738213539123535, Close=14.929642677307129, Adj Close=12.783873558044434, Volume=271269600),\n",
       " Row(Date=datetime.date(2012, 1, 6), Open=14.991786003112793, High=15.098214149475098, Low=14.972143173217773, Close=15.085714340209961, Adj Close=12.917512893676758, Volume=318292800),\n",
       " Row(Date=datetime.date(2012, 1, 9), Open=15.196429252624512, High=15.276785850524902, Low=15.048213958740234, Close=15.061785697937012, Adj Close=12.897022247314453, Volume=394024400)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Anomaly Detection: (Z-Score Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+------+------+---------+---------+------------------+\n",
      "|      Date|  Open|  High|   Low| Close|Adj Close|   Volume|           Z-Score|\n",
      "+----------+------+------+------+------+---------+---------+------------------+\n",
      "|2021-12-10|175.21|179.63|174.69|179.45|179.22166|115402700| 3.035868074034137|\n",
      "|2021-12-15|175.11| 179.5|172.31| 179.3|179.07185|131063300| 3.032304537672211|\n",
      "|2021-12-27|177.09|180.42|177.07|180.33|180.10054| 74919600|3.0567751207345415|\n",
      "|2021-12-28|180.16|181.33|178.53|179.29|179.06186| 79144300| 3.032066726903806|\n",
      "|2021-12-29|179.33|180.63|178.14|179.38|179.15175| 62348900|3.0342052112373765|\n",
      "|2021-12-30|179.47|180.57|178.09| 178.2|177.97325| 59773000|3.0061707292967053|\n",
      "|2022-01-03|177.83|182.88|177.71|182.01| 181.7784|104487900|3.0966881780537707|\n",
      "|2022-01-04|182.63|182.94|179.12| 179.7|179.47134| 99310400| 3.041807542981623|\n",
      "+----------+------+------+------+------+---------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean, stddev, abs\n",
    "\n",
    "stats = df_pyspark.select(mean(col(\"Close\")).alias(\"mean\"), stddev(col(\"Close\")).alias(\"stddev\")).collect()\n",
    "mean_close = stats[0][\"mean\"]\n",
    "stddev_close = stats[0][\"stddev\"]\n",
    "\n",
    "df_pyspark = df_pyspark.withColumn(\"Z-Score\", (col(\"Close\") - mean_close) / stddev_close)\n",
    "\n",
    "anomalies = df_pyspark.filter(abs(col(\"Z-Score\")) > 3)\n",
    "anomalies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies.write.option(\"header\", True).option(\"delimiter\", \",\").mode(\"overwrite\").csv(\"anomalies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Put the analysis result into Amazon S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.35.76-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting botocore<1.36.0,>=1.35.76 (from boto3)\n",
      "  Downloading botocore-1.35.76-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
      "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (from botocore<1.36.0,>=1.35.76->boto3) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (from botocore<1.36.0,>=1.35.76->boto3) (2.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/dataenv/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.76->boto3) (1.16.0)\n",
      "Downloading boto3-1.35.76-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.35.76-py3-none-any.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.35.76 botocore-1.35.76 jmespath-1.0.1 s3transfer-0.10.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "aws_access_key = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client(\n",
    "  service_name = 's3',\n",
    "  region_name = 'ca-central-1',\n",
    "  aws_access_key_id = aws_access_key,\n",
    "  aws_secret_access_key = aws_secret_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store anomalies to S3\n",
    "bucket_name = \"apple-stock-analysis\"\n",
    "s3_key = \"analysis-report/anomalies.csv\"\n",
    "file_name = \"./anomalies/part-00000-9ca57c60-6132-4558-ba0c-596a32e4e038-c000.csv\"\n",
    "\n",
    "s3.upload_file(file_name, bucket_name, s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store cleaned data to S3\n",
    "bucket_name = \"apple-stock-analysis\"\n",
    "s3_cleaned_key = \"analysis-report/Cleaned_Apple_Data.csv\"\n",
    "cleaned_data_file = \"./Cleaned_Apple_Data.csv\"\n",
    "\n",
    "s3.upload_file(cleaned_data_file, bucket_name, s3_cleaned_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
